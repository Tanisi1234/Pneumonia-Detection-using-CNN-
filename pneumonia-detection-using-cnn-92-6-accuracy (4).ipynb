{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810},{"sourceId":8255318,"sourceType":"datasetVersion","datasetId":4898967},{"sourceId":8255530,"sourceType":"datasetVersion","datasetId":4899139}],"dockerImageVersionId":29867,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Name : Tanisi Jha \n# Roll no: 221010251\n# Branch: ECE\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing the necessary libraries","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom keras.callbacks import ReduceLROnPlateau\nimport cv2\nimport os\nimport numpy as np","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2024-05-03T06:50:54.903506Z","iopub.execute_input":"2024-05-03T06:50:54.903890Z","iopub.status.idle":"2024-05-03T06:51:04.122755Z","shell.execute_reply.started":"2024-05-03T06:50:54.903844Z","shell.execute_reply":"2024-05-03T06:51:04.121661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Description of the Pneumonia Dataset\n**The dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (Pneumonia/Normal). There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia/Normal).\nChest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children’s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients’ routine clinical care.\nFor the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert.**","metadata":{}},{"cell_type":"code","source":"labels = ['PNEUMONIA', 'NORMAL']\nimg_size = 150\ndef get_training_data(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:51:29.450130Z","iopub.execute_input":"2024-05-03T06:51:29.450440Z","iopub.status.idle":"2024-05-03T06:51:29.458163Z","shell.execute_reply.started":"2024-05-03T06:51:29.450410Z","shell.execute_reply":"2024-05-03T06:51:29.456974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Dataset","metadata":{}},{"cell_type":"code","source":"train = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/train')\ntest = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/test')\nval = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/val')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-03T06:51:31.702248Z","iopub.execute_input":"2024-05-03T06:51:31.702567Z","iopub.status.idle":"2024-05-03T06:53:22.705417Z","shell.execute_reply.started":"2024-05-03T06:51:31.702537Z","shell.execute_reply":"2024-05-03T06:53:22.704138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization & Preprocessing","metadata":{}},{"cell_type":"code","source":"l = []\nfor i in train:\n    if(i[1] == 0):\n        l.append(\"Pneumonia\")\n    else:\n        l.append(\"Normal\")\nsns.set_style('darkgrid')\nsns.countplot(l)        ","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:53:49.031023Z","iopub.execute_input":"2024-05-03T06:53:49.031352Z","iopub.status.idle":"2024-05-03T06:53:49.229340Z","shell.execute_reply.started":"2024-05-03T06:53:49.031320Z","shell.execute_reply":"2024-05-03T06:53:49.228265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PREVIEW OF LUNG IMAGES","metadata":{}},{"cell_type":"code","source":"# Load and display 9 pneumonia images\nimport os\npneumonia_dir = \"/kaggle/input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA\"\npneumonia_images = os.listdir(pneumonia_dir)[:9]\n\nplt.figure(figsize=(15, 10))\nfor i, img_name in enumerate(pneumonia_images):\n    img_path = os.path.join(pneumonia_dir, img_name)\n    img = image.load_img(img_path, target_size=(120, 120))\n    plt.subplot(3, 3, i+1)\n    plt.imshow(img)\n    plt.title(\"Pneumonia\")\n    plt.axis('off')\nplt.show()\n\n# Load and display 9 normal images\nnormal_dir = \"/kaggle/input/chest-xray-pneumonia/chest_xray/train/NORMAL\"\nnormal_images = os.listdir(normal_dir)[:9]\n\nplt.figure(figsize=(15, 10))\nfor i, img_name in enumerate(normal_images):\n    img_path = os.path.join(normal_dir, img_name)\n    img = image.load_img(img_path, target_size=(120, 120))\n    plt.subplot(3, 3, i+1)\n    plt.imshow(img)\n    plt.title(\"Normal\")\n    plt.axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:37:08.609218Z","iopub.execute_input":"2024-05-03T07:37:08.609565Z","iopub.status.idle":"2024-05-03T07:37:12.534425Z","shell.execute_reply.started":"2024-05-03T07:37:08.609533Z","shell.execute_reply":"2024-05-03T07:37:12.533254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The data seems imbalanced . To increase the no. of training examples, we will use data augmentation**","metadata":{}},{"cell_type":"markdown","source":"**Previewing the images of both the classes**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (5,5))\nplt.imshow(train[0][0], cmap='gray')\nplt.title(labels[train[0][1]])\n\nplt.figure(figsize = (5,5))\nplt.imshow(train[-1][0], cmap='gray')\nplt.title(labels[train[-1][1]])","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:54:16.571398Z","iopub.execute_input":"2024-05-03T06:54:16.571732Z","iopub.status.idle":"2024-05-03T06:54:17.315550Z","shell.execute_reply.started":"2024-05-03T06:54:16.571701Z","shell.execute_reply":"2024-05-03T06:54:17.314632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = []\ny_train = []\n\nx_val = []\ny_val = []\n\nx_test = []\ny_test = []\n\nfor feature, label in train:\n    x_train.append(feature)\n    y_train.append(label)\n\nfor feature, label in test:\n    x_test.append(feature)\n    y_test.append(label)\n    \nfor feature, label in val:\n    x_val.append(feature)\n    y_val.append(label)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:54:21.090783Z","iopub.execute_input":"2024-05-03T06:54:21.091207Z","iopub.status.idle":"2024-05-03T06:54:21.106149Z","shell.execute_reply.started":"2024-05-03T06:54:21.091167Z","shell.execute_reply":"2024-05-03T06:54:21.104724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We perform a grayscale normalization to reduce the effect of illumination's differences.Moreover the CNN converges faster on [0..1] data than on [0..255].**","metadata":{}},{"cell_type":"code","source":"# Normalize the data\nx_train = np.array(x_train) / 255\nx_val = np.array(x_val) / 255\nx_test = np.array(x_test) / 255","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:54:26.340133Z","iopub.execute_input":"2024-05-03T06:54:26.340464Z","iopub.status.idle":"2024-05-03T06:54:27.014457Z","shell.execute_reply.started":"2024-05-03T06:54:26.340431Z","shell.execute_reply":"2024-05-03T06:54:27.013253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resize data for deep learning \nx_train = x_train.reshape(-1, img_size, img_size, 1)\ny_train = np.array(y_train)\n\nx_val = x_val.reshape(-1, img_size, img_size, 1)\ny_val = np.array(y_val)\n\nx_test = x_test.reshape(-1, img_size, img_size, 1)\ny_test = np.array(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:54:33.533090Z","iopub.execute_input":"2024-05-03T06:54:33.533410Z","iopub.status.idle":"2024-05-03T06:54:33.540940Z","shell.execute_reply.started":"2024-05-03T06:54:33.533378Z","shell.execute_reply":"2024-05-03T06:54:33.539748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation\n**In order to avoid overfitting problem, we need to expand artificially our dataset. We can make your existing dataset even larger. The idea is to alter the training data with small transformations to reproduce the variations.\nApproaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more.\nBy applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model.**","metadata":{}},{"cell_type":"markdown","source":"# Visualization of CNN in lung images\n","metadata":{}},{"cell_type":"code","source":"\nfrom IPython.display import Image\n\n# Replace 'path_to_image' with the actual path to your image file\nImage(filename='/kaggle/input/dataset-i/Screenshot 2024-04-28 220753.png')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:54:38.311578Z","iopub.execute_input":"2024-05-03T06:54:38.311893Z","iopub.status.idle":"2024-05-03T06:54:38.323763Z","shell.execute_reply.started":"2024-05-03T06:54:38.311863Z","shell.execute_reply":"2024-05-03T06:54:38.322398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\n# Replace 'path_to_image' with the actual path to your image file\nImage(filename='/kaggle/input/herherna/Screenshot 2024-04-28 230300.png')","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:54:43.338415Z","iopub.execute_input":"2024-05-03T06:54:43.338723Z","iopub.status.idle":"2024-05-03T06:54:43.352093Z","shell.execute_reply.started":"2024-05-03T06:54:43.338693Z","shell.execute_reply":"2024-05-03T06:54:43.351285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the data augmentation, i choosed to :\n1. Randomly rotate some training images by 30 degrees \n2. Randomly Zoom by 20% some training images\n3. Randomly shift images horizontally by 10% of the width \n4. Randomly shift images vertically by 10% of the height \n5. Randomly flip images horizontally.\nOnce our model is ready, we fit the training dataset.","metadata":{}},{"cell_type":"markdown","source":"# Training the Model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(Dropout(0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Flatten())\nmodel.add(Dense(units = 128 , activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units = 1 , activation = 'sigmoid'))\nmodel.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:54:48.574918Z","iopub.execute_input":"2024-05-03T06:54:48.575382Z","iopub.status.idle":"2024-05-03T06:54:49.120250Z","shell.execute_reply.started":"2024-05-03T06:54:48.575328Z","shell.execute_reply":"2024-05-03T06:54:49.119387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:54:57.761662Z","iopub.execute_input":"2024-05-03T06:54:57.762009Z","iopub.status.idle":"2024-05-03T06:54:57.768911Z","shell.execute_reply.started":"2024-05-03T06:54:57.761976Z","shell.execute_reply":"2024-05-03T06:54:57.767497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(datagen.flow(x_train,y_train, batch_size = 32) ,epochs = 12 , validation_data = datagen.flow(x_val, y_val) ,callbacks = [learning_rate_reduction])","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:30:52.653154Z","iopub.status.idle":"2024-05-03T07:30:52.654176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis after Model Training","metadata":{}},{"cell_type":"markdown","source":"**Some of the Correctly Predicted Classes**","metadata":{}},{"cell_type":"markdown","source":"**Some of the Incorrectly Predicted Classes**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Define directories\ntraining_dir = \"/kaggle/input/chest-xray-pneumonia/chest_xray/train\"\nvalidation_dir = \"/kaggle/input/chest-xray-pneumonia/chest_xray/val\"\ntest_dir = \"/kaggle/input/chest-xray-pneumonia/chest_xray/test\"\n\n# Data Augmentation\ntraining_generator = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\nvalidation_generator = ImageDataGenerator(rescale=1./255)\ntest_generator = ImageDataGenerator(rescale=1./255)\n\n# Flow from directory\ntrain_data = training_generator.flow_from_directory(training_dir,\n                                                    target_size=(120, 120),\n                                                    batch_size=32,\n                                                    class_mode='binary')\n\nvalidation_data = validation_generator.flow_from_directory(validation_dir,\n                                                            target_size=(120, 120),\n                                                            batch_size=32,\n                                                            class_mode='binary')\n\ntest_data = test_generator.flow_from_directory(test_dir,\n                                                target_size=(120, 120),\n                                                batch_size=1,\n                                                class_mode='binary',\n                                                shuffle=False)\n\n# Build CNN model\nmodel = Sequential([\n    Conv2D(32, (3, 3), input_shape=(120, 120, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(256, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(512, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(train_data, epochs=15, validation_data=validation_data)\n\n# Evaluate the model\ntest_loss, test_acc = model.evaluate(test_data, verbose=2)\nprint('\\nTest accuracy:', test_acc)\n\n# Confusion Matrix and Classification Report\ntest_data.reset()\npredictions = model.predict(test_data)\ny_pred = np.round(predictions)\ny_true = test_data.classes\n\nprint('\\nConfusion Matrix')\ncm = confusion_matrix(y_true, y_pred)\nprint(cm)\n\nprint('\\nClassification Report')\ntarget_names = ['Normal', 'Pneumonia']\nprint(classification_report(y_true, y_pred, target_names=target_names))\n\n# ROC Curve and AUC\nfpr, tpr, thresholds = roc_curve(y_true, predictions)\nauc = roc_auc_score(y_true, predictions)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\nplt.plot([0, 1], [0, 1], 'r--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc='lower right')\nplt.show()\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # for heatmap\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# ... (your existing code up to the confusion matrix calculation)\n\nprint('\\nConfusion Matrix')\ncm = confusion_matrix(y_true, y_pred)\nprint(cm)\n\n# Confusion Matrix with Color Representation\ngroup_names = ['Normal', 'Pneumonia']  # Adjust class names if needed\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.heatmap(cm, annot=True, cmap='Blues', fmt='d', ax=ax)  # Use 'Blues' for better visualization\nax.set_xlabel('Predicted Label')\nax.set_ylabel('True Label')\nax.set_title('Confusion Matrix')\nax.set_xticklabels(group_names, rotation=45, ha='right')\nax.set_yticklabels(group_names)\nplt.show()\n\n# ... (your existing code for classification report, ROC curve, etc.)\n\n#prediction\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\n\n# Load the image\nplt.figure(figsize=(20, 10))\n\n\n\nimg_path = \"/kaggle/input/chest-xray-pneumonia/chest_xray/train/NORMAL/IM-0115-0001.jpeg\"  # Replace with the path to your image\nimg = image.load_img(img_path, target_size=(120, 120))\nimg_array = image.img_to_array(img)\nimg_array = img_array / 255.0  # Normalize the image\n\n# Reshape the image to match the model's input shape\nimg_array = np.expand_dims(img_array, axis=0)\n\n# Make prediction\nprediction = model.predict(img_array)\n\n# Convert prediction probabilities to class labels\nthreshold = 0.5\npredicted_class = \"Pneumonia\" if prediction > threshold else \"Normal\"\n\n# Display the prediction result\nprint(\"Prediction:\", predicted_class)\n\n# Optionally, visualize the image\nplt.imshow(img)\nplt.axis('off')\nplt.title(\"Prediction: \" + predicted_class)\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:55:04.454605Z","iopub.execute_input":"2024-05-03T06:55:04.455087Z","iopub.status.idle":"2024-05-03T07:30:52.614770Z","shell.execute_reply.started":"2024-05-03T06:55:04.455044Z","shell.execute_reply":"2024-05-03T07:30:52.613475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming you have `correctly_predicted_indices` and `incorrectly_predicted_indices` defined somewhere in your code\n\nmax_display_images = 10  # Maximum number of images to display\ncorrectly_predicted_images = []\nincorrectly_predicted_images = []\n\n# Collect correctly predicted images\nfor index in correctly_predicted_indices[:max_display_images]:\n    img_path = test_data.filepaths[index]\n    img = image.load_img(img_path, target_size=(120, 120))\n    correctly_predicted_images.append((img, 0))  # Predicted class=0, Actual class=0\n\n# Collect incorrectly predicted images\nfor index in incorrectly_predicted_indices[:max_display_images]:\n    img_path = test_data.filepaths[index]\n    img = image.load_img(img_path, target_size=(120, 120))\n    incorrectly_predicted_images.append((img, 1))  # Predicted class=1, Actual class=0\n\n# Visualize Correctly and Incorrectly Predicted Images\nplt.figure(figsize=(15, 8))\nplt.suptitle('Correctly Predicted Images', fontsize=16)\nfor i, (img, _) in enumerate(correctly_predicted_images):\n    plt.subplot(2, max_display_images//2, i + 1)\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title('Predicted Class=0\\nActual Class=0')\n\nplt.figure(figsize=(15, 8))\nplt.suptitle('Incorrectly Predicted Images', fontsize=16)\nfor i, (img, _) in enumerate(incorrectly_predicted_images):\n    plt.subplot(2, max_display_images//2, i + 1)\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title('Predicted Class=1\\nActual Class=0')\n\nplt.show()\n\n# Print the number of correctly and incorrectly predicted images\nprint(\"Number of correctly predicted images:\", len(correctly_predicted_indices))\nprint(\"Number of incorrectly predicted images:\", len(incorrectly_predicted_indices))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:39:09.157258Z","iopub.execute_input":"2024-05-03T07:39:09.157580Z","iopub.status.idle":"2024-05-03T07:39:09.196078Z","shell.execute_reply.started":"2024-05-03T07:39:09.157550Z","shell.execute_reply":"2024-05-03T07:39:09.193510Z"},"trusted":true},"execution_count":null,"outputs":[]}]}